{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f821c3-f27b-4917-899a-a7894d1930e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ------------\n",
      "accelerate                1.10.1\n",
      "aiohappyeyeballs          2.6.1\n",
      "aiohttp                   3.13.0\n",
      "aiosignal                 1.4.0\n",
      "annotated-types           0.7.0\n",
      "anyio                     4.11.0\n",
      "argon2-cffi               25.1.0\n",
      "argon2-cffi-bindings      25.1.0\n",
      "arrow                     1.4.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.5\n",
      "attrs                     25.4.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.14.2\n",
      "bitsandbytes              0.48.1\n",
      "bleach                    6.2.0\n",
      "certifi                   2025.10.5\n",
      "cffi                      2.0.0\n",
      "charset-normalizer        3.4.4\n",
      "comm                      0.2.3\n",
      "cut-cross-entropy         25.1.1\n",
      "datasets                  4.2.0\n",
      "debugpy                   1.8.17\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "diffusers                 0.35.2\n",
      "dill                      0.4.0\n",
      "docstring_parser          0.17.0\n",
      "executing                 2.2.1\n",
      "fastjsonschema            2.21.2\n",
      "filelock                  3.20.0\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.8.0\n",
      "fsspec                    2025.9.0\n",
      "h11                       0.16.0\n",
      "hf_transfer               0.1.9\n",
      "hf-xet                    1.1.10\n",
      "httpcore                  1.0.9\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.35.3\n",
      "idna                      3.11\n",
      "importlib_metadata        8.7.0\n",
      "ipykernel                 7.0.1\n",
      "ipython                   9.6.0\n",
      "ipython_pygments_lexers   1.1.1\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.6\n",
      "json5                     0.12.1\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.25.1\n",
      "jsonschema-specifications 2025.9.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.9.1\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.3.0\n",
      "jupyter_server            2.17.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.4.9\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "lark                      1.3.0\n",
      "markdown-it-py            4.0.0\n",
      "MarkupSafe                3.0.3\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "mistral_common            1.8.5\n",
      "mistune                   3.1.4\n",
      "mpmath                    1.3.0\n",
      "msgspec                   0.19.0\n",
      "multidict                 6.7.0\n",
      "multiprocess              0.70.16\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.5\n",
      "notebook                  7.4.7\n",
      "notebook_shim             0.2.4\n",
      "numpy                     2.3.4\n",
      "nvidia-cublas-cu12        12.8.4.1\n",
      "nvidia-cuda-cupti-cu12    12.8.90\n",
      "nvidia-cuda-nvrtc-cu12    12.8.93\n",
      "nvidia-cuda-runtime-cu12  12.8.90\n",
      "nvidia-cudnn-cu12         9.10.2.21\n",
      "nvidia-cufft-cu12         11.3.3.83\n",
      "nvidia-cufile-cu12        1.13.1.3\n",
      "nvidia-curand-cu12        10.3.9.90\n",
      "nvidia-cusolver-cu12      11.7.3.90\n",
      "nvidia-cusparse-cu12      12.5.8.93\n",
      "nvidia-cusparselt-cu12    0.7.1\n",
      "nvidia-nccl-cu12          2.27.3\n",
      "nvidia-nvjitlink-cu12     12.8.93\n",
      "nvidia-nvshmem-cu12       3.3.20\n",
      "nvidia-nvtx-cu12          12.8.90\n",
      "overrides                 7.7.0\n",
      "packaging                 25.0\n",
      "pandas                    2.3.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.5\n",
      "peft                      0.17.1\n",
      "pexpect                   4.9.0\n",
      "pillow                    12.0.0\n",
      "pip                       25.2\n",
      "platformdirs              4.5.0\n",
      "prometheus_client         0.23.1\n",
      "prompt_toolkit            3.0.52\n",
      "propcache                 0.4.1\n",
      "protobuf                  6.33.0\n",
      "psutil                    7.1.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   21.0.0\n",
      "pycountry                 24.6.1\n",
      "pycparser                 2.23\n",
      "pydantic                  2.12.2\n",
      "pydantic_core             2.41.4\n",
      "pydantic-extra-types      2.10.6\n",
      "Pygments                  2.19.2\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        4.0.0\n",
      "pytz                      2025.2\n",
      "PyYAML                    6.0.3\n",
      "pyzmq                     27.1.0\n",
      "referencing               0.37.0\n",
      "regex                     2025.9.18\n",
      "reportlab                 4.4.4\n",
      "requests                  2.32.5\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rfc3987-syntax            1.1.0\n",
      "rich                      14.2.0\n",
      "rpds-py                   0.27.1\n",
      "safetensors               0.6.2\n",
      "Send2Trash                1.8.3\n",
      "sentencepiece             0.2.1\n",
      "setuptools                80.9.0\n",
      "shtab                     1.7.2\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.8\n",
      "stack-data                0.6.3\n",
      "sympy                     1.14.0\n",
      "terminado                 0.18.1\n",
      "tiktoken                  0.12.0\n",
      "tinycss2                  1.4.0\n",
      "tokenizers                0.22.1\n",
      "torch                     2.8.0\n",
      "torchao                   0.14.0\n",
      "torchvision               0.23.0\n",
      "tornado                   6.5.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.56.2\n",
      "triton                    3.4.0\n",
      "trl                       0.23.0\n",
      "typeguard                 4.4.4\n",
      "typing_extensions         4.15.0\n",
      "typing-inspection         0.4.2\n",
      "tyro                      0.9.35\n",
      "tzdata                    2025.2\n",
      "unsloth                   2025.10.3\n",
      "unsloth_zoo               2025.10.3\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.5.0\n",
      "wcwidth                   0.2.14\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.9.0\n",
      "wheel                     0.45.1\n",
      "xformers                  0.0.32.post2\n",
      "xxhash                    3.6.0\n",
      "yarl                      1.22.0\n",
      "zipp                      3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e7ca1e-d663-4488-bb6d-9f20846b5be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mrnzero321/qwenenv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e638cc-06a0-4e94-bdc2-a0fa8fc3d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c523095d-0ad8-4871-b105-f7036898b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataProcessor:\n",
    "    \"\"\"Download and process IMDb datasets\"\"\"\n",
    "    \n",
    "    # Dictionary containing all the download URLs for IMDb datasets\n",
    "    # Each key is a friendly name, each value is the actual download URL\n",
    "    URLS = {\n",
    "        'title_basics': 'https://datasets.imdbws.com/title.basics.tsv.gz',  # Basic movie info (title, year, type)\n",
    "        'title_principals': 'https://datasets.imdbws.com/title.principals.tsv.gz',  # Cast and crew members\n",
    "        'name_basics': 'https://datasets.imdbws.com/name.basics.tsv.gz',  # People's names and info\n",
    "        'title_crew': 'https://datasets.imdbws.com/title.crew.tsv.gz',  # Directors and writers list (NEW!)\n",
    "        'title_ratings': 'https://datasets.imdbws.com/title.ratings.tsv.gz'  # Movie ratings\n",
    "    }\n",
    "    \n",
    "    def __init__(self, data_dir='imdb_data'):\n",
    "        \"\"\"\n",
    "        Initialize the processor\n",
    "        data_dir: folder name where we'll store downloaded files\n",
    "        \"\"\"\n",
    "        # Convert the folder name string to a Path object for easier manipulation\n",
    "        self.data_dir = Path(data_dir)\n",
    "        # Create the directory if it doesn't exist yet (exist_ok=True means no error if it exists)\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def download_datasets(self):\n",
    "        \"\"\"Download all required IMDb datasets from the internet\"\"\"\n",
    "        # Log that we're starting the download process\n",
    "        logger.info(\"Starting dataset downloads...\")\n",
    "        \n",
    "        # Loop through each dataset name and its URL\n",
    "        for name, url in self.URLS.items():\n",
    "            # Create the full path where this file will be saved\n",
    "            output_path = self.data_dir / f\"{name}.tsv.gz\"\n",
    "            # Check if the file already exists on disk\n",
    "            if output_path.exists():\n",
    "                # If it exists, skip downloading and tell the user\n",
    "                logger.info(f\"{name} already exists, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Log that we're downloading this specific dataset\n",
    "            logger.info(f\"Downloading {name}...\")\n",
    "            # Make an HTTP GET request to download the file (stream=True means download in chunks)\n",
    "            response = requests.get(url, stream=True)\n",
    "            # Open the output file in write-binary mode\n",
    "            with open(output_path, 'wb') as f:\n",
    "                # Copy the downloaded data to the file in chunks\n",
    "                shutil.copyfileobj(response.raw, f)\n",
    "            # Log successful download with a checkmark\n",
    "            logger.info(f\"✓ {name} downloaded\")\n",
    "    \n",
    "    def load_and_filter_data(self):\n",
    "        \"\"\"Load and filter IMDb data for movies only (not TV shows, etc.)\"\"\"\n",
    "        # Log that we're starting to load the datasets\n",
    "        logger.info(\"Loading datasets...\")\n",
    "        \n",
    "        # Load title basics (contains movie metadata like title, year, type)\n",
    "        logger.info(\"Processing title.basics...\")\n",
    "        # Read the compressed TSV file into a pandas DataFrame\n",
    "        titles = pd.read_csv(\n",
    "            self.data_dir / 'title_basics.tsv.gz',  # File path\n",
    "            sep='\\t',  # Tab-separated values\n",
    "            na_values='\\\\N',  # IMDb uses '\\N' to represent missing data\n",
    "            low_memory=False  # Don't try to optimize memory (more reliable)\n",
    "        )\n",
    "        \n",
    "        # Filter: only movies, have year, minimum info\n",
    "        # Create a copy of rows that meet all our criteria\n",
    "        movies = titles[\n",
    "            (titles['titleType'] == 'movie') &  # Only movies (not TV shows, episodes, etc.)\n",
    "            (titles['startYear'].notna()) &  # Must have a year\n",
    "            (titles['startYear'] != '\\\\N')  # Year is not the missing data marker\n",
    "        ].copy()  # Create a copy to avoid warnings about modifying views\n",
    "        \n",
    "        # Convert the startYear column from text to numbers (some might fail, set to NaN)\n",
    "        movies['startYear'] = pd.to_numeric(movies['startYear'], errors='coerce')\n",
    "        # Keep only movies between 1920 and 2024 (reasonable range)\n",
    "        movies = movies[movies['startYear'].between(1920, 2024)]\n",
    "        \n",
    "        # Log how many movies we found (with comma thousands separator)\n",
    "        logger.info(f\"Found {len(movies):,} movies\")\n",
    "        \n",
    "        # Load name basics (contains information about actors, directors, writers)\n",
    "        logger.info(\"Processing name.basics...\")\n",
    "        # Read the names dataset into a DataFrame\n",
    "        names = pd.read_csv(\n",
    "            self.data_dir / 'name_basics.tsv.gz',  # File path\n",
    "            sep='\\t',  # Tab-separated\n",
    "            na_values='\\\\N',  # Missing data marker\n",
    "            low_memory=False  # Don't optimize memory\n",
    "        )\n",
    "        \n",
    "        # Load principals (links people to movies with their roles)\n",
    "        logger.info(\"Processing title.principals...\")\n",
    "        # Read the principals dataset\n",
    "        principals = pd.read_csv(\n",
    "            self.data_dir / 'title_principals.tsv.gz',  # File path\n",
    "            sep='\\t',  # Tab-separated\n",
    "            na_values='\\\\N',  # Missing data marker\n",
    "            low_memory=False  # Don't optimize memory\n",
    "        )\n",
    "        \n",
    "        # Filter: actors, actresses, directors, writers, producers only\n",
    "        # Create a copy with only the crew/cast roles we care about\n",
    "        crew_cast = principals[principals['category'].isin([\n",
    "            'actor',  # Male actors\n",
    "            'actress',  # Female actors (IMDb separates them)\n",
    "            'director',  # Directors\n",
    "            'writer',  # Writers\n",
    "            'producer'  # Producers\n",
    "        ])].copy()  # Create a copy\n",
    "        \n",
    "        # Log how many crew/cast entries we found\n",
    "        logger.info(f\"Found {len(crew_cast):,} crew/cast entries\")\n",
    "        \n",
    "        # Load crew data (separate file with directors & writers organized by movie)\n",
    "        logger.info(\"Processing title.crew...\")\n",
    "        # Read the crew dataset\n",
    "        crew = pd.read_csv(\n",
    "            self.data_dir / 'title_crew.tsv.gz',  # File path\n",
    "            sep='\\t',  # Tab-separated\n",
    "            na_values='\\\\N',  # Missing data marker\n",
    "            low_memory=False  # Don't optimize memory\n",
    "        )\n",
    "        \n",
    "        # Log how many crew records we found\n",
    "        logger.info(f\"Found {len(crew):,} crew records\")\n",
    "        \n",
    "        # Return all four DataFrames for further processing\n",
    "        return movies, names, crew_cast, crew\n",
    "    \n",
    "    def create_knowledge_base(self, movies, names, crew_cast, crew):\n",
    "        \"\"\"Create structured knowledge base for query generation by merging all data\"\"\"\n",
    "        # Log that we're building the knowledge base\n",
    "        logger.info(\"Building knowledge base...\")\n",
    "        \n",
    "        # Merge cast/crew with movie info\n",
    "        # This combines the crew_cast data with movie details (title, year, genres)\n",
    "        crew_movies = crew_cast.merge(\n",
    "            movies[['tconst', 'primaryTitle', 'startYear', 'genres']],  # Columns we need from movies\n",
    "            on='tconst',  # Join on movie ID\n",
    "            how='inner'  # Only keep rows that exist in both DataFrames\n",
    "        )\n",
    "        \n",
    "        # Merge with person names\n",
    "        # Add the actual names of people to our dataset\n",
    "        crew_movies = crew_movies.merge(\n",
    "            names[['nconst', 'primaryName']],  # Person ID and name\n",
    "            on='nconst',  # Join on person ID\n",
    "            how='inner'  # Only keep rows that exist in both\n",
    "        )\n",
    "        \n",
    "        # Clean data - remove rows where name is missing\n",
    "        crew_movies = crew_movies[crew_movies['primaryName'].notna()]\n",
    "        # Remove rows where movie title is missing\n",
    "        crew_movies = crew_movies[crew_movies['primaryTitle'].notna()]\n",
    "        \n",
    "        # Focus on people with reasonable filmography (3-500 credits)\n",
    "        # Count how many times each person appears in each role\n",
    "        person_counts = crew_movies.groupby(['primaryName', 'category']).size()\n",
    "        # Keep only people with 3-500 credits (removes obscure and fake entries)\n",
    "        valid_people = person_counts[(person_counts >= 3) & (person_counts <= 500)].index\n",
    "        # Filter our dataset to only include these valid people\n",
    "        crew_movies = crew_movies[crew_movies.set_index(['primaryName', 'category']).index.isin(valid_people)]\n",
    "        \n",
    "        # Log statistics about our knowledge base\n",
    "        logger.info(f\"Knowledge base: {len(crew_movies):,} records\")\n",
    "        # Count and log number of actors/actresses\n",
    "        logger.info(f\"  Actors/Actresses: {len(crew_movies[crew_movies['category'].isin(['actor', 'actress'])]):,}\")\n",
    "        # Count and log number of directors\n",
    "        logger.info(f\"  Directors: {len(crew_movies[crew_movies['category'] == 'director']):,}\")\n",
    "        # Count and log number of writers\n",
    "        logger.info(f\"  Writers: {len(crew_movies[crew_movies['category'] == 'writer']):,}\")\n",
    "        # Count and log number of producers\n",
    "        logger.info(f\"  Producers: {len(crew_movies[crew_movies['category'] == 'producer']):,}\")\n",
    "        \n",
    "        # Return the merged and cleaned knowledge base\n",
    "        return crew_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd46d4a-6ce7-4cc7-bca7-ef69a4bc5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAGenerator:\n",
    "    \"\"\"Generate training Q&A pairs (with crew support) for fine-tuning LLMs\"\"\"\n",
    "    \n",
    "    def __init__(self, knowledge_base: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the QA generator\n",
    "        knowledge_base: the processed movie/crew dataset\n",
    "        \"\"\"\n",
    "        # Store the knowledge base as an instance variable\n",
    "        self.kb = knowledge_base\n",
    "        # Initialize an empty list to store generated question-answer pairs\n",
    "        self.qa_pairs = []\n",
    "        \n",
    "    def generate_temporal_queries(self, n=200):\n",
    "        \"\"\"\n",
    "        Single-hop: Person filmography in specific year\n",
    "        Example: \"How many movies did Tom Hanks act in 1994?\"\n",
    "        \"\"\"\n",
    "        # Log what we're doing\n",
    "        logger.info(\"Generating temporal queries...\")\n",
    "        \n",
    "        # Mix of actors and directors for variety\n",
    "        # Get unique actor names from the knowledge base\n",
    "        actors = self.kb[self.kb['category'].isin(['actor', 'actress'])]['primaryName'].unique()\n",
    "        # Get unique director names\n",
    "        directors = self.kb[self.kb['category'] == 'director']['primaryName'].unique()\n",
    "        \n",
    "        # Combine them: 70% actors, 30% directors\n",
    "        people = list(actors[:int(n*0.7)]) + list(directors[:int(n*0.3)])\n",
    "        # Randomize the order so we don't always get the same people\n",
    "        random.shuffle(people)\n",
    "        \n",
    "        # Loop through the selected people (up to n of them)\n",
    "        for person in people[:n]:\n",
    "            # Determine their role (actor/director/etc)\n",
    "            # Get all rows for this person\n",
    "            person_data = self.kb[self.kb['primaryName'] == person]\n",
    "            # If no data found, skip to next person\n",
    "            if len(person_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get their primary role (first row's category)\n",
    "            role = person_data['category'].iloc[0]\n",
    "            # Pick a random year from their filmography\n",
    "            year = random.choice(person_data['startYear'].dropna().unique())\n",
    "            # Get all movies they did in that specific year\n",
    "            movies_that_year = person_data[person_data['startYear'] == year]\n",
    "            \n",
    "            # If they didn't do any movies that year, skip\n",
    "            if len(movies_that_year) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get the list of movie titles from that year\n",
    "            movie_list = movies_that_year['primaryTitle'].tolist()\n",
    "            \n",
    "            # Generate question and answer based on their role\n",
    "            if role in ['actor', 'actress']:\n",
    "                # Question for actors\n",
    "                question = f\"How many movies did {person} act in {int(year)}?\"\n",
    "                # Start of answer\n",
    "                answer = f\"{person} appeared in {len(movie_list)} movie(s) in {int(year)}:\\n\"\n",
    "            elif role == 'director':\n",
    "                # Question for directors\n",
    "                question = f\"How many movies did {person} direct in {int(year)}?\"\n",
    "                answer = f\"{person} directed {len(movie_list)} movie(s) in {int(year)}:\\n\"\n",
    "            elif role == 'writer':\n",
    "                # Question for writers\n",
    "                question = f\"How many movies did {person} write in {int(year)}?\"\n",
    "                answer = f\"{person} wrote {len(movie_list)} movie(s) in {int(year)}:\\n\"\n",
    "            else:  # producer or other\n",
    "                # Question for producers\n",
    "                question = f\"How many movies did {person} produce in {int(year)}?\"\n",
    "                answer = f\"{person} produced {len(movie_list)} movie(s) in {int(year)}:\\n\"\n",
    "            \n",
    "            # Add numbered list of movies (up to 10)\n",
    "            answer += \"\\n\".join([f\"{i+1}. {title}\" for i, title in enumerate(movie_list[:10])])\n",
    "            \n",
    "            # If there are more than 10 movies, indicate that\n",
    "            if len(movie_list) > 10:\n",
    "                answer += f\"\\n... and {len(movie_list) - 10} more\"\n",
    "            \n",
    "            # Add this Q&A pair to our collection in ChatML format\n",
    "            self.qa_pairs.append({\n",
    "                'messages': [\n",
    "                    {'role': 'user', 'content': question},\n",
    "                    {'role': 'assistant', 'content': answer}\n",
    "                ],\n",
    "                'metadata': {\n",
    "                    'type': 'temporal_single',\n",
    "                    'complexity': 'single-hop'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # If we've generated enough, stop\n",
    "            if len(self.qa_pairs) >= n:\n",
    "                break\n",
    "    \n",
    "    def generate_range_queries(self, n=200):\n",
    "        \"\"\"\n",
    "        Two-hop: Movies in year range\n",
    "        Example: \"Which films did Steven Spielberg direct between 1990-1995?\"\n",
    "        \"\"\"\n",
    "        # Log what we're generating\n",
    "        logger.info(\"Generating range queries...\")\n",
    "        \n",
    "        # Get all unique people from knowledge base\n",
    "        people = self.kb['primaryName'].unique()\n",
    "        # Shuffle to randomize\n",
    "        random.shuffle(people)\n",
    "        \n",
    "        # Try more people than needed to ensure we get enough valid queries\n",
    "        for person in people[:n*2]:  # Try more to get enough valid ones\n",
    "            # Get all data for this person\n",
    "            person_data = self.kb[self.kb['primaryName'] == person]\n",
    "            # Get sorted list of years they worked\n",
    "            years = sorted(person_data['startYear'].dropna().unique())\n",
    "            \n",
    "            # Skip if they don't have at least 3 years of work\n",
    "            if len(years) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Get their primary role\n",
    "            role = person_data['category'].iloc[0]\n",
    "            # Pick a random starting point in their career\n",
    "            start_idx = random.randint(0, len(years) - 3)\n",
    "            # Pick a random range size (3-5 years)\n",
    "            range_size = random.randint(3, min(5, len(years) - start_idx))\n",
    "            \n",
    "            # Convert the start and end years to integers\n",
    "            start_year = int(years[start_idx])\n",
    "            end_year = int(years[start_idx + range_size - 1])\n",
    "            \n",
    "            # Get all movies in this year range\n",
    "            movies_in_range = person_data[\n",
    "                person_data['startYear'].between(start_year, end_year)\n",
    "            ]\n",
    "            \n",
    "            # Get the list of movie titles\n",
    "            movie_list = movies_in_range['primaryTitle'].tolist()\n",
    "            \n",
    "            # Choose appropriate verb based on role\n",
    "            if role in ['actor', 'actress']:\n",
    "                verb = \"appear in\"\n",
    "            elif role == 'director':\n",
    "                verb = \"direct\"\n",
    "            elif role == 'writer':\n",
    "                verb = \"write\"\n",
    "            else:  # producer\n",
    "                verb = \"produce\"\n",
    "            \n",
    "            # Create the question\n",
    "            question = f\"Which films did {person} {verb} between {start_year}-{end_year}?\"\n",
    "            # Start the answer with count\n",
    "            answer = f\"{person} worked on {len(movie_list)} film(s) between {start_year}-{end_year}:\\n\"\n",
    "            # Add numbered list with titles and years (up to 10)\n",
    "            answer += \"\\n\".join([f\"{i+1}. {title} ({int(year)})\" \n",
    "                                for i, (title, year) in enumerate(\n",
    "                                    zip(movies_in_range['primaryTitle'][:10],\n",
    "                                        movies_in_range['startYear'][:10]))])\n",
    "            \n",
    "            # If more than 10, indicate that\n",
    "            if len(movie_list) > 10:\n",
    "                answer += f\"\\n... and {len(movie_list) - 10} more\"\n",
    "            \n",
    "            # Add this Q&A pair to collection in ChatML format\n",
    "            self.qa_pairs.append({\n",
    "                'messages': [\n",
    "                    {'role': 'user', 'content': question},\n",
    "                    {'role': 'assistant', 'content': answer}\n",
    "                ],\n",
    "                'metadata': {\n",
    "                    'type': 'temporal_range',\n",
    "                    'complexity': 'two-hop'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # If we've generated enough, stop\n",
    "            if len(self.qa_pairs) >= n:\n",
    "                break\n",
    "    \n",
    "    def generate_actor_director_queries(self, n=150):\n",
    "        \"\"\"\n",
    "        Three-hop: Actor working with specific director\n",
    "        Example: \"Which movies did Tom Hanks act in that were directed by Steven Spielberg?\"\n",
    "        \"\"\"\n",
    "        # Log what we're generating\n",
    "        logger.info(\"Generating actor-director collaboration queries...\")\n",
    "        \n",
    "        # Counter for successfully generated queries\n",
    "        generated = 0\n",
    "        # Counter for total attempts\n",
    "        attempts = 0\n",
    "        # Maximum attempts before giving up\n",
    "        max_attempts = n * 20\n",
    "        \n",
    "        # Keep trying until we have enough queries or hit max attempts\n",
    "        while generated < n and attempts < max_attempts:\n",
    "            # Increment attempt counter\n",
    "            attempts += 1\n",
    "            \n",
    "            # Pick a random movie from the knowledge base\n",
    "            movie = self.kb.sample(1).iloc[0]\n",
    "            # Get its unique ID\n",
    "            movie_id = movie['tconst']\n",
    "            \n",
    "            # Get all people who worked on this movie\n",
    "            movie_crew = self.kb[self.kb['tconst'] == movie_id]\n",
    "            \n",
    "            # Get all actors who worked on this movie\n",
    "            actors = movie_crew[movie_crew['category'].isin(['actor', 'actress'])]['primaryName'].unique()\n",
    "            # Get all directors who worked on this movie\n",
    "            directors = movie_crew[movie_crew['category'] == 'director']['primaryName'].unique()\n",
    "            \n",
    "            # Skip if no actors or directors found\n",
    "            if len(actors) == 0 or len(directors) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Pick a random actor from this movie\n",
    "            actor = random.choice(actors)\n",
    "            # Pick a random director from this movie\n",
    "            director = random.choice(directors)\n",
    "            \n",
    "            # Find all movies where this actor worked (as actor)\n",
    "            actor_movies = set(self.kb[\n",
    "                (self.kb['primaryName'] == actor) & \n",
    "                (self.kb['category'].isin(['actor', 'actress']))\n",
    "            ]['tconst'])\n",
    "            \n",
    "            # Find all movies this director directed\n",
    "            director_movies = set(self.kb[\n",
    "                (self.kb['primaryName'] == director) & \n",
    "                (self.kb['category'] == 'director')\n",
    "            ]['tconst'])\n",
    "            \n",
    "            # Find intersection: movies where actor worked AND director directed\n",
    "            collabs = actor_movies & director_movies\n",
    "            \n",
    "            # Skip if no collaborations found\n",
    "            if len(collabs) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get movie details for all collaborations\n",
    "            # Group by movie ID and take first row (removes duplicates)\n",
    "            collab_movies = self.kb[self.kb['tconst'].isin(collabs)].groupby('tconst').first()\n",
    "            \n",
    "            # Create the question\n",
    "            question = f\"Which movies did {actor} act in that were directed by {director}?\"\n",
    "            # Start the answer with count\n",
    "            answer = f\"{actor} acted in {len(collabs)} movie(s) directed by {director}:\\n\"\n",
    "            # Add numbered list of movies (up to 10)\n",
    "            answer += \"\\n\".join([f\"{i+1}. {row['primaryTitle']} ({int(row['startYear'])})\" \n",
    "                                for i, (_, row) in enumerate(collab_movies.head(10).iterrows())])\n",
    "            \n",
    "            # If more than 10 collaborations, indicate that\n",
    "            if len(collabs) > 10:\n",
    "                answer += f\"\\n... and {len(collabs) - 10} more\"\n",
    "            \n",
    "            # Add this Q&A pair to collection in ChatML format\n",
    "            self.qa_pairs.append({\n",
    "                'messages': [\n",
    "                    {'role': 'user', 'content': question},\n",
    "                    {'role': 'assistant', 'content': answer}\n",
    "                ],\n",
    "                'metadata': {\n",
    "                    'type': 'actor_director',\n",
    "                    'complexity': 'three-hop'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # Increment successful generation counter\n",
    "            generated += 1\n",
    "    \n",
    "    def generate_costar_queries(self, n=200):\n",
    "        \"\"\"\n",
    "        Three-hop: Find movies with specific actor pairs\n",
    "        Example: \"Which movies did Leonardo DiCaprio and Kate Winslet act together in?\"\n",
    "        \"\"\"\n",
    "        # Log what we're generating\n",
    "        logger.info(\"Generating co-star queries...\")\n",
    "        \n",
    "        # Group by movie: for each movie, get list of all actors\n",
    "        movie_actors = self.kb[self.kb['category'].isin(['actor', 'actress'])].groupby('tconst')['primaryName'].apply(list)\n",
    "        # Get basic movie info (grouped by movie ID, take first row)\n",
    "        movie_info = self.kb.groupby('tconst').first()\n",
    "        \n",
    "        # Counter for successfully generated queries\n",
    "        generated = 0\n",
    "        # Counter for total attempts\n",
    "        attempts = 0\n",
    "        # Maximum attempts before giving up\n",
    "        max_attempts = n * 10\n",
    "        \n",
    "        # Keep trying until we have enough queries or hit max attempts\n",
    "        while generated < n and attempts < max_attempts:\n",
    "            # Increment attempt counter\n",
    "            attempts += 1\n",
    "            \n",
    "            # Pick a random movie that has at least 2 actors\n",
    "            movie_id = random.choice(movie_actors[movie_actors.apply(len) >= 2].index)\n",
    "            # Get the list of actors in this movie\n",
    "            actors = movie_actors[movie_id]\n",
    "            \n",
    "            # Skip if less than 2 actors (shouldn't happen but safety check)\n",
    "            if len(actors) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Pick 2 random actors from this movie\n",
    "            actor1, actor2 = random.sample(actors, 2)\n",
    "            \n",
    "            # Find all movies where actor1 acted\n",
    "            actor1_movies = set(self.kb[\n",
    "                (self.kb['primaryName'] == actor1) & \n",
    "                (self.kb['category'].isin(['actor', 'actress']))\n",
    "            ]['tconst'])\n",
    "            \n",
    "            # Find all movies where actor2 acted\n",
    "            actor2_movies = set(self.kb[\n",
    "                (self.kb['primaryName'] == actor2) & \n",
    "                (self.kb['category'].isin(['actor', 'actress']))\n",
    "            ]['tconst'])\n",
    "            \n",
    "            # Find intersection: movies where both actors appeared\n",
    "            common_movies = actor1_movies & actor2_movies\n",
    "            \n",
    "            # Skip if they never worked together\n",
    "            if len(common_movies) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get details of their collaborations\n",
    "            collabs = self.kb[self.kb['tconst'].isin(common_movies)].groupby('tconst').first()\n",
    "            \n",
    "            # Create the question\n",
    "            question = f\"Which movies did {actor1} and {actor2} act together in?\"\n",
    "            # Start the answer with count\n",
    "            answer = f\"{actor1} and {actor2} appeared together in {len(common_movies)} movie(s):\\n\"\n",
    "            # Add numbered list of movies (up to 10)\n",
    "            answer += \"\\n\".join([f\"{i+1}. {row['primaryTitle']} ({int(row['startYear'])})\" \n",
    "                                for i, (_, row) in enumerate(collabs.head(10).iterrows())])\n",
    "            \n",
    "            # If more than 10 collaborations, indicate that\n",
    "            if len(common_movies) > 10:\n",
    "                answer += f\"\\n... and {len(common_movies) - 10} more\"\n",
    "            \n",
    "            # Add this Q&A pair to collection in ChatML format\n",
    "            self.qa_pairs.append({\n",
    "                'messages': [\n",
    "                    {'role': 'user', 'content': question},\n",
    "                    {'role': 'assistant', 'content': answer}\n",
    "                ],\n",
    "                'metadata': {\n",
    "                    'type': 'costar',\n",
    "                    'complexity': 'three-hop'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # Increment successful generation counter\n",
    "            generated += 1\n",
    "    \n",
    "    def generate_director_comparison_queries(self, n=100):\n",
    "        \"\"\"\n",
    "        Aggregation: Compare directors' output in a specific decade\n",
    "        Example: \"Who directed more movies in the 1990s: Spielberg or Scorsese?\"\n",
    "        \"\"\"\n",
    "        # Log what we're generating\n",
    "        logger.info(\"Generating director comparison queries...\")\n",
    "        \n",
    "        # Get all unique directors from knowledge base\n",
    "        directors = self.kb[self.kb['category'] == 'director']['primaryName'].unique()\n",
    "        # Shuffle to randomize\n",
    "        random.shuffle(directors)\n",
    "        \n",
    "        # Counter for successfully generated queries\n",
    "        generated = 0\n",
    "        \n",
    "        # Loop through directors in pairs (i and i+1)\n",
    "        for i in range(0, len(directors)-1, 2):\n",
    "            # If we have enough queries, stop\n",
    "            if generated >= n:\n",
    "                break\n",
    "                \n",
    "            # Get the two directors to compare\n",
    "            director1 = directors[i]\n",
    "            director2 = directors[i+1]\n",
    "            \n",
    "            # Get all movies directed by director1\n",
    "            dir1_data = self.kb[\n",
    "                (self.kb['primaryName'] == director1) & \n",
    "                (self.kb['category'] == 'director')\n",
    "            ]\n",
    "            # Get all movies directed by director2\n",
    "            dir2_data = self.kb[\n",
    "                (self.kb['primaryName'] == director2) & \n",
    "                (self.kb['category'] == 'director')\n",
    "            ]\n",
    "            \n",
    "            # Skip if either director has less than 3 movies (not enough data)\n",
    "            if len(dir1_data) < 3 or len(dir2_data) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Pick a random decade to compare\n",
    "            decade = random.choice([1980, 1990, 2000, 2010])\n",
    "            \n",
    "            # Get director1's movies in this decade (decade to decade+9 = 10 years)\n",
    "            dir1_decade = dir1_data[dir1_data['startYear'].between(decade, decade+9)]\n",
    "            # Get director2's movies in this decade\n",
    "            dir2_decade = dir2_data[dir2_data['startYear'].between(decade, decade+9)]\n",
    "            \n",
    "            # Skip if neither director worked in this decade\n",
    "            if len(dir1_decade) == 0 and len(dir2_decade) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Count movies for each director\n",
    "            count1 = len(dir1_decade)\n",
    "            count2 = len(dir2_decade)\n",
    "            \n",
    "            # Create the question\n",
    "            question = f\"Who directed more movies in the {decade}s: {director1} or {director2}?\"\n",
    "            \n",
    "            # Create the answer based on who directed more\n",
    "            if count1 > count2:\n",
    "                # Director1 directed more\n",
    "                answer = f\"{director1} directed more movies in the {decade}s with {count1} films compared to {director2}'s {count2} films.\"\n",
    "            elif count2 > count1:\n",
    "                # Director2 directed more\n",
    "                answer = f\"{director2} directed more movies in the {decade}s with {count2} films compared to {director1}'s {count1} films.\"\n",
    "            else:\n",
    "                # They directed the same amount\n",
    "                answer = f\"Both {director1} and {director2} directed the same number of films in the {decade}s ({count1} each).\"\n",
    "            \n",
    "            # Add this Q&A pair to collection in ChatML format\n",
    "            self.qa_pairs.append({\n",
    "                'messages': [\n",
    "                    {'role': 'user', 'content': question},\n",
    "                    {'role': 'assistant', 'content': answer}\n",
    "                ],\n",
    "                'metadata': {\n",
    "                    'type': 'director_comparison',\n",
    "                    'complexity': 'aggregation'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # Increment successful generation counter\n",
    "            generated += 1\n",
    "    \n",
    "    def generate_genre_queries(self, n=150):\n",
    "        \"\"\"\n",
    "        Aggregation: Genre-specific queries\n",
    "        Example: \"How many Action movies has Tom Cruise appeared in?\"\n",
    "        \"\"\"\n",
    "        # Log what we're generating\n",
    "        logger.info(\"Generating genre queries...\")\n",
    "        \n",
    "        # Get all unique people from knowledge base\n",
    "        people = self.kb['primaryName'].unique()\n",
    "        # Shuffle to randomize\n",
    "        random.shuffle(people)\n",
    "        \n",
    "        # List of genres to query about\n",
    "        genres = ['Action', 'Drama', 'Comedy', 'Thriller', 'Horror', 'Sci-Fi']\n",
    "        \n",
    "        # Loop through people (up to n)\n",
    "        for person in people[:n]:\n",
    "            # Get all data for this person\n",
    "            person_data = self.kb[self.kb['primaryName'] == person]\n",
    "            # Get their primary role\n",
    "            role = person_data['category'].iloc[0]\n",
    "            \n",
    "            # Pick a random genre from our list\n",
    "            genre = random.choice(genres)\n",
    "            \n",
    "            # Count movies in that genre (genres column contains comma-separated genres)\n",
    "            genre_movies = person_data[\n",
    "                person_data['genres'].str.contains(genre, na=False)\n",
    "            ]\n",
    "            \n",
    "            # Skip if they have no movies in this genre\n",
    "            if len(genre_movies) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Create question and answer based on role\n",
    "            if role in ['actor', 'actress']:\n",
    "                question = f\"How many {genre} movies has {person} appeared in?\"\n",
    "                answer = f\"{person} has appeared in {len(genre_movies)} {genre} movie(s).\"\n",
    "            elif role == 'director':\n",
    "                question = f\"How many {genre} movies has {person} directed?\"\n",
    "                answer = f\"{person} has directed {len(genre_movies)} {genre} movie(s).\"\n",
    "            else:\n",
    "                # Skip other roles (writers, producers)\n",
    "                continue\n",
    "            \n",
    "            # Add this Q&A pair to collection in ChatML format\n",
    "            self.qa_pairs.append({\n",
    "                'messages': [\n",
    "                    {'role': 'user', 'content': question},\n",
    "                    {'role': 'assistant', 'content': answer}\n",
    "                ],\n",
    "                'metadata': {\n",
    "                    'type': 'genre_count',\n",
    "                    'complexity': 'aggregation'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # If we've generated enough, stop\n",
    "            if len(self.qa_pairs) >= n:\n",
    "                break\n",
    "    \n",
    "    def generate_all(self, total_samples=2000):\n",
    "        \"\"\"\n",
    "        Generate dataset with custom distribution:\n",
    "        30% single-hop, 40% two-hop, 20% three-hop, 10% aggregation\n",
    "        \"\"\"\n",
    "        # Single-hop: temporal queries\n",
    "        self.generate_temporal_queries(n=int(total_samples * 0.30))\n",
    "        \n",
    "        # Two-hop: range queries\n",
    "        self.generate_range_queries(n=int(total_samples * 0.40))\n",
    "        \n",
    "        # Three-hop: actor-director & co-star combined\n",
    "        # Split 20%: 10% actor-director, 10% co-star\n",
    "        self.generate_actor_director_queries(n=int(total_samples * 0.10))\n",
    "        self.generate_costar_queries(n=int(total_samples * 0.10))\n",
    "        \n",
    "        # Aggregation/statistical: director comparison & genre\n",
    "        # Split 10%: 5% director comparison, 5% genre\n",
    "        self.generate_director_comparison_queries(n=int(total_samples * 0.05))\n",
    "        self.generate_genre_queries(n=int(total_samples * 0.05))\n",
    "        \n",
    "        logger.info(f\"Generated {len(self.qa_pairs)} total Q&A pairs\")\n",
    "        return self\n",
    "\n",
    "    def split_and_save(self, output_dir='data'):\n",
    "        \"\"\"\n",
    "        Split dataset into train (80%), validation (10%), test (10%)\n",
    "        and save to separate JSONL files in ChatML format\n",
    "        \"\"\"\n",
    "        # Log that we're starting the split and save process\n",
    "        logger.info(f\"Splitting {len(self.qa_pairs)} Q&A pairs into train/val/test...\")\n",
    "        \n",
    "        # Shuffle the data to randomize\n",
    "        random.shuffle(self.qa_pairs)\n",
    "        \n",
    "        # Calculate split indices\n",
    "        total = len(self.qa_pairs)\n",
    "        train_end = int(total * 0.80)\n",
    "        val_end = int(total * 0.90)\n",
    "        \n",
    "        # Split the data\n",
    "        train_data = self.qa_pairs[:train_end]\n",
    "        val_data = self.qa_pairs[train_end:val_end]\n",
    "        test_data = self.qa_pairs[val_end:]\n",
    "        \n",
    "        # Save each split to a separate file\n",
    "        splits = {\n",
    "            'train.jsonl': train_data,\n",
    "            'validation.jsonl': val_data,\n",
    "            'test.jsonl': test_data\n",
    "        }\n",
    "        \n",
    "        for filename, data in splits.items():\n",
    "            filepath = f\"{output_dir}/{filename}\"\n",
    "            logger.info(f\"Saving {len(data)} examples to {filepath}...\")\n",
    "            \n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                for qa in data:\n",
    "                    # Write only the messages (ChatML format), not metadata\n",
    "                    f.write(json.dumps({'messages': qa['messages']}, ensure_ascii=False) + '\\n')\n",
    "            \n",
    "            logger.info(f\"✓ Saved {len(data)} examples to {filepath}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Dataset Split Summary\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Train:      {len(train_data)} examples ({len(train_data)/total*100:.1f}%)\")\n",
    "        print(f\"Validation: {len(val_data)} examples ({len(val_data)/total*100:.1f}%)\")\n",
    "        print(f\"Test:       {len(test_data)} examples ({len(test_data)/total*100:.1f}%)\")\n",
    "        print(f\"Total:      {total} examples\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"\n",
    "        Generate and display statistics about the generated dataset\n",
    "        Shows distribution of query types and complexities\n",
    "        \"\"\"\n",
    "        # Extract metadata for analysis\n",
    "        metadata_list = [qa['metadata'] for qa in self.qa_pairs]\n",
    "        df = pd.DataFrame(metadata_list)\n",
    "        \n",
    "        # Print header for statistics\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Dataset Statistics\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Print total number of Q&A pairs\n",
    "        print(f\"\\nTotal Q&A pairs: {len(self.qa_pairs)}\")\n",
    "        \n",
    "        # Print distribution by query type\n",
    "        print(\"\\nDistribution by Query Type:\")\n",
    "        # Count how many of each type we have\n",
    "        type_counts = df['type'].value_counts()\n",
    "        # Loop through each type and its count\n",
    "        for query_type, count in type_counts.items():\n",
    "            # Calculate percentage of total\n",
    "            percentage = (count / len(df)) * 100\n",
    "            # Print type, count, and percentage\n",
    "            print(f\"  {query_type}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Print distribution by complexity level\n",
    "        print(\"\\nDistribution by Complexity:\")\n",
    "        # Count how many of each complexity level we have\n",
    "        complexity_counts = df['complexity'].value_counts()\n",
    "        # Loop through each complexity and its count\n",
    "        for complexity, count in complexity_counts.items():\n",
    "            # Calculate percentage of total\n",
    "            percentage = (count / len(df)) * 100\n",
    "            # Print complexity, count, and percentage\n",
    "            print(f\"  {complexity}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Print closing line\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    def sample_examples(self, n=5):\n",
    "        \"\"\"\n",
    "        Display random sample of generated Q&A pairs for quality checking\n",
    "        n: number of examples to display\n",
    "        \"\"\"\n",
    "        # Print header\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Sample Q&A Pairs (showing {n} random examples)\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        # Get n random samples from our Q&A pairs\n",
    "        samples = random.sample(self.qa_pairs, min(n, len(self.qa_pairs)))\n",
    "        \n",
    "        # Loop through each sample with index\n",
    "        for i, qa in enumerate(samples, 1):\n",
    "            # Print example number and type/complexity\n",
    "            print(f\"Example {i} [{qa['metadata']['type']} - {qa['metadata']['complexity']}]\")\n",
    "            # Print separator line\n",
    "            print(\"-\" * 50)\n",
    "            # Print the question with Q: prefix\n",
    "            print(f\"Q: {qa['messages'][0]['content']}\")\n",
    "            # Print the answer with A: prefix\n",
    "            print(f\"A: {qa['messages'][1]['content']}\")\n",
    "            # Print blank line between examples\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd639638-9a34-41b3-a9a5-8a01263163ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting dataset downloads...\n",
      "INFO:__main__:title_basics already exists, skipping...\n",
      "INFO:__main__:title_principals already exists, skipping...\n",
      "INFO:__main__:name_basics already exists, skipping...\n",
      "INFO:__main__:title_crew already exists, skipping...\n",
      "INFO:__main__:title_ratings already exists, skipping...\n",
      "INFO:__main__:Loading datasets...\n",
      "INFO:__main__:Processing title.basics...\n",
      "INFO:__main__:Found 590,284 movies\n",
      "INFO:__main__:Processing name.basics...\n",
      "INFO:__main__:Processing title.principals...\n",
      "INFO:__main__:Found 66,450,257 crew/cast entries\n",
      "INFO:__main__:Processing title.crew...\n",
      "INFO:__main__:Found 11,987,707 crew records\n",
      "INFO:__main__:Building knowledge base...\n",
      "INFO:__main__:Knowledge base: 3,786,277 records\n",
      "INFO:__main__:  Actors/Actresses: 2,599,190\n",
      "INFO:__main__:  Directors: 394,638\n",
      "INFO:__main__:  Writers: 449,289\n",
      "INFO:__main__:  Producers: 343,160\n",
      "INFO:__main__:Generating temporal queries...\n",
      "INFO:__main__:Generating range queries...\n",
      "INFO:__main__:Generating actor-director collaboration queries...\n",
      "INFO:__main__:Generating co-star queries...\n",
      "INFO:__main__:Generating director comparison queries...\n",
      "INFO:__main__:Generating genre queries...\n",
      "INFO:__main__:Generated 1301 total Q&A pairs\n",
      "INFO:__main__:Splitting 1301 Q&A pairs into train/val/test...\n",
      "INFO:__main__:Saving 1040 examples to ./train.jsonl...\n",
      "INFO:__main__:✓ Saved 1040 examples to ./train.jsonl\n",
      "INFO:__main__:Saving 130 examples to ./validation.jsonl...\n",
      "INFO:__main__:✓ Saved 130 examples to ./validation.jsonl\n",
      "INFO:__main__:Saving 131 examples to ./test.jsonl...\n",
      "INFO:__main__:✓ Saved 131 examples to ./test.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Dataset Statistics\n",
      "==================================================\n",
      "\n",
      "Total Q&A pairs: 1301\n",
      "\n",
      "Distribution by Query Type:\n",
      "  temporal_single: 600 (46.1%)\n",
      "  temporal_range: 200 (15.4%)\n",
      "  actor_director: 200 (15.4%)\n",
      "  costar: 200 (15.4%)\n",
      "  director_comparison: 100 (7.7%)\n",
      "  genre_count: 1 (0.1%)\n",
      "\n",
      "Distribution by Complexity:\n",
      "  single-hop: 600 (46.1%)\n",
      "  three-hop: 400 (30.7%)\n",
      "  two-hop: 200 (15.4%)\n",
      "  aggregation: 101 (7.8%)\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Sample Q&A Pairs (showing 5 random examples)\n",
      "==================================================\n",
      "\n",
      "Example 1 [actor_director - three-hop]\n",
      "--------------------------------------------------\n",
      "Q: Which movies did Rooholah Mofidi act in that were directed by Armaees Aghamaliyan?\n",
      "A: Rooholah Mofidi acted in 1 movie(s) directed by Armaees Aghamaliyan:\n",
      "1. The Humans (1964)\n",
      "\n",
      "Example 2 [temporal_single - single-hop]\n",
      "--------------------------------------------------\n",
      "Q: How many movies did George Edwardes-Hall write in 1920?\n",
      "A: George Edwardes-Hall wrote 4 movie(s) in 1920:\n",
      "1. Foolish Monte Carlo\n",
      "2. Desire\n",
      "3. Desire\n",
      "4. The Temptress\n",
      "\n",
      "Example 3 [temporal_single - single-hop]\n",
      "--------------------------------------------------\n",
      "Q: How many movies did Henry Otto direct in 1925?\n",
      "A: Henry Otto directed 1 movie(s) in 1925:\n",
      "1. The Ancient Mariner\n",
      "\n",
      "Example 4 [temporal_range - two-hop]\n",
      "--------------------------------------------------\n",
      "Q: Which films did Marcie Hume produce between 2012-2019?\n",
      "A: Marcie Hume worked on 3 film(s) between 2012-2019:\n",
      "1. Sex Story: Fifty Shades of Grey (2012)\n",
      "2. Magicians: Life in the Impossible (2016)\n",
      "3. What's Eating Ralphie May? (2019)\n",
      "\n",
      "Example 5 [temporal_single - single-hop]\n",
      "--------------------------------------------------\n",
      "Q: How many movies did Boris Karloff act in 1947?\n",
      "A: Boris Karloff appeared in 4 movie(s) in 1947:\n",
      "1. Dick Tracy Meets Gruesome\n",
      "2. Lured\n",
      "3. The Secret Life of Walter Mitty\n",
      "4. Unconquered\n",
      "\n",
      "\n",
      "==================================================\n",
      "Dataset Split Summary\n",
      "==================================================\n",
      "Train:      1040 examples (79.9%)\n",
      "Validation: 130 examples (10.0%)\n",
      "Test:       131 examples (10.1%)\n",
      "Total:      1301 examples\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Updated usage code\n",
    "# Step 0: Create processor\n",
    "processor = IMDbDataProcessor()\n",
    "# Step 1: Download datasets\n",
    "processor.download_datasets()\n",
    "# Step 2: Load and filter data\n",
    "movies, names, crew_cast, crew = processor.load_and_filter_data()\n",
    "# Step 3: Create knowledge base\n",
    "knowledge_base = processor.create_knowledge_base(movies, names, crew_cast, crew)\n",
    "# Step 4: Initialize QAGenerator\n",
    "generator = QAGenerator(knowledge_base)\n",
    "# Step 5: Generate Q&A pairs\n",
    "generator.generate_all(total_samples=2000)\n",
    "# Step 6: Check statistics\n",
    "generator.get_statistics()\n",
    "# Step 7: Sample some examples\n",
    "generator.sample_examples(n=5)\n",
    "# Step 8: Split and save to train/validation/test files\n",
    "generator.split_and_save(output_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004699f8-97ad-4e6b-8491-24581d3e95f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "udev             15G     0   15G   0% /dev\n",
      "tmpfs           3.0G  556K  3.0G   1% /run\n",
      "/dev/sda1       148G   18G  124G  13% /\n",
      "tmpfs            15G     0   15G   0% /dev/shm\n",
      "tmpfs           5.0M     0  5.0M   0% /run/lock\n",
      "/dev/sda15      124M   12M  113M  10% /boot/efi\n",
      "tmpfs           3.0G     0  3.0G   0% /run/user/1000\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e0c5a-7d39-4f14-b978-9c5f1ecf30d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qwenenv)",
   "language": "python",
   "name": "qwenenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
